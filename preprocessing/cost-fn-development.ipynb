{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix = pd.read_csv('../data/algo_testing_data.csv')\n",
    "od_matrix['hash'] = [frozenset(x) for x in zip(od_matrix['Origin'], od_matrix['Dest'])]\n",
    "od_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in solution and cities data\n",
    "sol = pd.read_csv('../out/solution.csv')\n",
    "cities_geom = gpd.read_file('../data/us-major-cities/USA_Major_Cities.shp')\n",
    "og_crs = cities_geom.crs\n",
    "cities_cols = ['NAME', 'ST', 'geometry']\n",
    "cities_geom[cities_cols]\n",
    "\n",
    "sol_cols = sol.columns\n",
    "# first add the coords of the origin city\n",
    "temp = sol.merge(\n",
    "    cities_geom[cities_cols],\n",
    "    how='inner',\n",
    "    left_on=['city_origin', 'state_origin'],\n",
    "    right_on=['NAME', 'ST']\n",
    ").rename(columns={'geometry': 'pt_origin'})\n",
    "# then add the coords of the dest city\n",
    "temp = temp.merge(\n",
    "    cities_geom[cities_cols],\n",
    "    how='inner',\n",
    "    left_on=['city_dest', 'state_dest'],\n",
    "    right_on=['NAME', 'ST']\n",
    ").rename(columns={'geometry': 'pt_dest'})\n",
    "sol_geom = temp[['pt_origin', 'pt_dest']]\n",
    "# create line segments from city points\n",
    "sol_geom['geometry'] = sol_geom.apply(\n",
    "    lambda row: shapely.LineString((row['pt_origin'], row['pt_dest'])),\n",
    "    axis='columns'\n",
    ")\n",
    "\n",
    "sol_geo = gpd.GeoDataFrame(sol, geometry=sol_geom['geometry'], crs=og_crs)  # type: ignore\n",
    "states = gpd.read_file('../data/us-states/States_shapefile.shp').to_crs(epsg=3395)\n",
    "# remove AK and HI\n",
    "states: gpd.GeoDataFrame = states[(states['State_Code'] != 'AK') & (states['State_Code'] != 'HI')]  # type: ignore\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True, figsize=(20, 20))\n",
    "ax1 = states.plot(ax=ax1, cmap='Pastel2')\n",
    "sol_geo.to_crs(epsg=3395).plot(ax=ax1, column='co2_g', cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(sol_geo, source='Origin', target='Dest', edge_attr='NonStopKm')\n",
    "nx.draw_networkx(G, pos=nx.planar_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe of shortest paths between every pair of cities in the rail network\n",
    "# paths_df will contain one row for each leg of each shortest path\n",
    "paths_tuples: list[tuple[str, dict[str, list[str]]]] = nx.all_pairs_dijkstra_path(G, weight='NonStopKm')\n",
    "visited_paths: set[frozenset] = set()\n",
    "paths_df = pd.DataFrame(columns=['hash', 'Origin', 'Dest', 'path_origin', 'path_dest'])\n",
    "pathsList = []\n",
    "\n",
    "for (origin, paths_dict) in paths_tuples:\n",
    "    for (dest, path) in paths_dict.items():\n",
    "        pathKey = frozenset([origin, dest])\n",
    "        # skip 0-length and already-seen paths\n",
    "        # TODO skip paths between airports in same city\n",
    "        if origin == dest or pathKey in visited_paths:\n",
    "            continue\n",
    "        visited_paths.add(pathKey)\n",
    "        pathsList.append(path) # todo remove\n",
    "        \n",
    "        # create small dataframe to represent this path; each row is an edge\n",
    "        df = pd.DataFrame(path, columns=['Origin'])\n",
    "        df['Dest'] = df['Origin'].shift(-1)\n",
    "        df = df.dropna()\n",
    "        df['path_origin'] = path[0]\n",
    "        df['path_dest'] = path[-1]\n",
    "        # hash is an order-independent identifier for a single edge: (JFK,LAX) == (LAX,JFK)\n",
    "        df['hash'] = [frozenset(x) for x in zip(df['Origin'], df['Dest'])]\n",
    "        paths_df = pd.concat([paths_df, df], axis='index')\n",
    "\n",
    "\n",
    "paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge paths_df with the OD-matrix to obtain attributes for each rail segment present in the network\n",
    "paths_df = paths_df.merge(od_matrix.drop(columns=['Origin', 'Dest']), on='hash', how='left', validate='m:1')\n",
    "paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group paths_df by unique path\n",
    "paths_df['path_hash'] = [frozenset(x) for x in zip(paths_df['path_origin'], paths_df['path_dest'])]\n",
    "path_groups = paths_df.groupby('path_hash')[[\n",
    "    'NonStopKm',\n",
    "    'hsr_time_hr',\n",
    "    'co2_g_hsr',\n",
    "]]\n",
    "\n",
    "# for each path, sum the following:\n",
    "# - travel time by HSR\n",
    "# - travel distance by HSR -> becomes hsr_km (distance by rail journey)\n",
    "# - co2 emitted by HSR journey\n",
    "hsr_metrics = path_groups.sum()\n",
    "# for each path, count the following:\n",
    "# - number of legs in the rail journey\n",
    "hsr_metrics['hsr_legs'] = path_groups.count()['NonStopKm']\n",
    "hsr_metrics = hsr_metrics.rename(columns={'NonStopKm': 'hsr_km'}).reset_index()\n",
    "hsr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge OD-matrix back into aggregated path data to link metrics for HSR journey/path with\n",
    "#  corresponding metrics for direct flight journey\n",
    "hsr_metrics = hsr_metrics.merge(\n",
    "    od_matrix[[\n",
    "        'hash',\n",
    "        'Origin', 'Dest',\n",
    "        'NonStopKm',\n",
    "        'Passengers',\n",
    "        'flight_time_hr',\n",
    "        'co2_g_flight',\n",
    "        # 'city_origin', 'state_origin', 'pop_origin',\n",
    "        # 'city_dest', 'state_dest', 'pop_dest',\n",
    "    ]],\n",
    "    left_on='path_hash',\n",
    "    right_on='hash',\n",
    "    how='outer', # todo\n",
    "    validate='1:1',\n",
    "    # indicator=True,\n",
    ").rename(columns={'Passengers': 'total_passengers', 'NonStopKm': 'flight_km'}).drop(columns=['hash'])\n",
    "hsr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsr_metrics_dev = hsr_metrics.copy()\n",
    "\n",
    "# add 3 hours for travel time to/from airport, security, gate times, etc.\n",
    "hsr_metrics_dev['flight_time_hr'] += 3\n",
    "\n",
    "hsr_metrics_dev['delta_travel_time'] = (hsr_metrics_dev['hsr_time_hr'] - hsr_metrics_dev['flight_time_hr']).fillna(0)\n",
    "\n",
    "# number of passengers who will opt to take this HSR path instead of the corresponding flight\n",
    "# assumed proportion of passengers who will opt to take HSR over flying:\n",
    "# let t = time(HSR) / time(flight):\n",
    "# prop0: t<1.0 = 1.0 = 100% of passengers\n",
    "# prop1: 1.00-1.25 = 0.9\n",
    "# prop2: 1.25-1.50 = 0.8\n",
    "# prop3: 1.50-2.0 = 0.7\n",
    "# prop4: t>2.0 = 0.5\n",
    "\n",
    "t = hsr_metrics_dev['hsr_time_hr'] / hsr_metrics_dev['flight_time_hr']\n",
    "prop0 = t > 0\n",
    "prop1 = t > 1\n",
    "prop2 = t > 1.25\n",
    "prop3 = t > 1.50\n",
    "prop4 = t > 2.0\n",
    "\n",
    "hsr_passengers = pd.Series(index=hsr_metrics_dev['total_passengers'].index)\n",
    "hsr_passengers.loc[prop0] = hsr_metrics_dev['total_passengers']\n",
    "hsr_passengers.loc[prop1] = hsr_metrics_dev['total_passengers'] * 0.9\n",
    "hsr_passengers.loc[prop2] = hsr_metrics_dev['total_passengers'] * 0.8\n",
    "hsr_passengers.loc[prop3] = hsr_metrics_dev['total_passengers'] * 0.7\n",
    "hsr_passengers.loc[prop4] = hsr_metrics_dev['total_passengers'] * 0.5\n",
    "hsr_metrics_dev['hsr_passengers'] = hsr_passengers.fillna(0)\n",
    "\n",
    "hsr_metrics_dev['flight_passengers'] = hsr_metrics_dev['total_passengers'] - hsr_metrics_dev['hsr_passengers']\n",
    "\n",
    "# source: https://travelandclimate.org/transport-calculations\n",
    "# pkm = passenger-kilometer\n",
    "# units: g/pkm\n",
    "co2_pkm_flight = 133  # from 'Scheduled flight (Economy)'\n",
    "co2_pkm_hsr = 24  # from 'Electric train (Europe)'\n",
    "# change in co2 when switching from flight -> HSR\n",
    "hsr_metrics_dev['new_co2'] = (\n",
    "    (co2_pkm_flight * hsr_metrics_dev['flight_passengers'] * hsr_metrics_dev['hsr_km'])\n",
    "    + (co2_pkm_hsr * hsr_metrics_dev['hsr_passengers'] * hsr_metrics_dev['flight_km'])\n",
    ").fillna(hsr_metrics_dev['co2_g_flight'])\n",
    "\n",
    "hsr_metrics_dev['delta_co2'] = hsr_metrics_dev['new_co2'] - hsr_metrics_dev['co2_g_flight']\n",
    "hsr_metrics_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cols = [\n",
    "    'delta_travel_time',\n",
    "    'hsr_passengers',\n",
    "    'flight_passengers',\n",
    "    'total_passengers',\n",
    "    'new_co2',\n",
    "    'delta_co2',\n",
    "]\n",
    "\n",
    "# min-max normalization:\n",
    "score_df = hsr_metrics_dev[score_cols]\n",
    "normalized = (score_df - score_df.min()) / (score_df.max() - score_df.min())\n",
    "sums = normalized.sum()\n",
    "sums = score_df.sum()\n",
    "cost = sums['new_co2'] - sums['hsr_passengers']\n",
    "cost\n",
    "\n",
    "# NOTE: construction cost USD is not included in this dataframe because it would be overcounted\n",
    "#  -- many paths may share the same rail segments!\n",
    "# to get total construction cost, simply sum up cost of segments in state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
