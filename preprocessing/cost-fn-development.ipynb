{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix = pd.read_csv('../data/algo_testing_data.csv', index_col=0)\n",
    "od_matrix['hash'] = [frozenset(x) for x in zip(od_matrix['Origin'], od_matrix['Dest'])]\n",
    "od_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in solution and cities data\n",
    "sol = pd.read_csv('../out/solution.csv')\n",
    "cities_geom = gpd.read_file('../data/us-major-cities/USA_Major_Cities.shp')\n",
    "og_crs = cities_geom.crs\n",
    "cities_cols = ['NAME', 'ST', 'geometry']\n",
    "cities_geom[cities_cols]\n",
    "\n",
    "sol_cols = sol.columns\n",
    "# first add the coords of the origin city\n",
    "temp = sol.merge(\n",
    "    cities_geom[cities_cols],\n",
    "    how='inner',\n",
    "    left_on=['city_origin', 'state_origin'],\n",
    "    right_on=['NAME', 'ST']\n",
    ").rename(columns={'geometry': 'pt_origin'})\n",
    "# then add the coords of the dest city\n",
    "temp = temp.merge(\n",
    "    cities_geom[cities_cols],\n",
    "    how='inner',\n",
    "    left_on=['city_dest', 'state_dest'],\n",
    "    right_on=['NAME', 'ST']\n",
    ").rename(columns={'geometry': 'pt_dest'})\n",
    "sol_geom = temp[['pt_origin', 'pt_dest']]\n",
    "# create line segments from city points\n",
    "sol_geom['geometry'] = sol_geom.apply(\n",
    "    lambda row: shapely.LineString((row['pt_origin'], row['pt_dest'])),\n",
    "    axis='columns'\n",
    ")\n",
    "\n",
    "sol_geo = gpd.GeoDataFrame(sol, geometry=sol_geom['geometry'], crs=og_crs)  # type: ignore\n",
    "states = gpd.read_file('../data/us-states/States_shapefile.shp').to_crs(epsg=3395)\n",
    "# remove AK and HI\n",
    "states: gpd.GeoDataFrame = states[(states['State_Code'] != 'AK') & (states['State_Code'] != 'HI')]  # type: ignore\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True, figsize=(20, 20))\n",
    "ax1 = states.plot(ax=ax1, cmap='Pastel2')\n",
    "sol_geo.to_crs(epsg=3395).plot(ax=ax1, column='co2_g', cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(sol_geo, source='Origin', target='Dest', edge_attr='NonStopKm')\n",
    "nx.draw_networkx(G, pos=nx.planar_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe of shortest paths between every pair of cities in the rail network\n",
    "# paths_df will contain one row for each leg of each shortest path\n",
    "paths_tuples: list[tuple[str, dict[str, list[str]]]] = nx.all_pairs_dijkstra_path(G, weight='NonStopKm')\n",
    "visited_paths: set[frozenset] = set()\n",
    "paths_df = pd.DataFrame(columns=['hash', 'Origin', 'Dest', 'path_origin', 'path_dest'])\n",
    "pathsList = []\n",
    "\n",
    "for (origin, paths_dict) in paths_tuples:\n",
    "    for (dest, path) in paths_dict.items():\n",
    "        pathKey = frozenset([origin, dest])\n",
    "        # skip 0-length and already-seen paths\n",
    "        # TODO skip paths between airports in same city\n",
    "        if origin == dest or pathKey in visited_paths:\n",
    "            continue\n",
    "        visited_paths.add(pathKey)\n",
    "        pathsList.append(path) # todo remove\n",
    "        \n",
    "        # create small dataframe to represent this path; each row is an edge\n",
    "        df = pd.DataFrame(path, columns=['Origin'])\n",
    "        df['Dest'] = df['Origin'].shift(-1)\n",
    "        df = df.dropna()\n",
    "        df['path_origin'] = path[0]\n",
    "        df['path_dest'] = path[-1]\n",
    "        # hash is an order-independent identifier for a single edge: (JFK,LAX) == (LAX,JFK)\n",
    "        df['hash'] = [frozenset(x) for x in zip(df['Origin'], df['Dest'])]\n",
    "        paths_df = pd.concat([paths_df, df], axis='index')\n",
    "\n",
    "\n",
    "paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge paths_df with the OD-matrix to obtain attributes for each rail segment present in the network\n",
    "paths_df = paths_df.merge(od_matrix.drop(columns=['Origin', 'Dest']), on='hash', how='left', validate='m:1')\n",
    "paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group paths_df by unique path\n",
    "paths_df['path_hash'] = [frozenset(x) for x in zip(paths_df['path_origin'], paths_df['path_dest'])]\n",
    "path_groups = paths_df.groupby('path_hash')[[\n",
    "    'NonStopKm',\n",
    "    'hsr_time_hr',\n",
    "    'co2_g_hsr'\n",
    "]]\n",
    "\n",
    "# for each path, sum the following:\n",
    "# - travel time by HSR\n",
    "# - travel distance by HSR -> becomes hsr_km (distance by rail journey)\n",
    "# - co2 emitted by HSR journey\n",
    "hsr_metrics = path_groups.sum()\n",
    "# for each path, count the following:\n",
    "# - number of legs in the rail journey\n",
    "hsr_metrics['hsr_legs'] = path_groups.count()['NonStopKm']\n",
    "hsr_metrics = hsr_metrics.rename(columns={'NonStopKm': 'hsr_km'}).reset_index()\n",
    "hsr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge OD-matrix back into aggregated path data to link metrics for HSR journey/path\n",
    "# with corresponding metrics for direct flight journey\n",
    "hsr_metrics = hsr_metrics.merge(\n",
    "    od_matrix[[\n",
    "        'hash',\n",
    "        'Origin', 'Dest',\n",
    "        'Passengers',\n",
    "        'flight_time_hr',\n",
    "        'co2_g_flight',\n",
    "        # 'city_origin', 'state_origin', 'pop_origin',\n",
    "        # 'city_dest', 'state_dest', 'pop_dest',\n",
    "    ]],\n",
    "    left_on='path_hash',\n",
    "    right_on='hash',\n",
    "    how='left',\n",
    "    validate='1:1',\n",
    "    # indicator=True,\n",
    ").drop(columns=['hash'])\n",
    "hsr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsr_metrics_dev = hsr_metrics.copy()\n",
    "# hsr_metrics_dev.to_csv('../out/temp.csv', index=False)\n",
    "\n",
    "# add 3 hours for travel time to/from airport, security, gate times, etc.\n",
    "hsr_metrics_dev['flight_time_hr'] += 3\n",
    "\n",
    "hsr_metrics_dev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
